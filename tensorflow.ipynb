{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e56dda-c6b1-49d7-8b8d-39f2666ce524",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad0bc1-679c-408f-b61e-21d96ead764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = datagen.flow_from_directory('data/train', target_size=(224, 224), batch_size=32, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff7328-a00c-4534-a2c5-71455ff2ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d0516-c657-4c16-96d2-df262cb57f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774c25e-357d-4c5b-94a6-b2ee8ede01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fbee0-a1c1-4c40-880c-71909abf2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=25, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b89fb9-7de3-4fd4-b1c8-e1d9c6f39cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "predictions = model.predict(test_generator)\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef428e5-0b7b-4d04-9436-718200a32f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74779a-7e39-4674-9df9-2f0fc509c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Visualize the model architecture\n",
    "plot_model(model, to_file='vgg16_model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c8113-8b04-43c5-8831-5a482a01a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=15, horizontal_flip=True)\n",
    "datagen.fit(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae26ba-f7fe-48fe-aa68-edcf00ec1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# Add custom layers on top of the pre-trained model\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes for CIFAR-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a4426-73f6-4160-900d-0d274a0ffa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475f6aa-87d4-4578-a1ad-5f90264e130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy and loss over epochs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2386067-ee50-43ef-bf58-9049b4a12edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Predict on test images\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Function to display images with predicted labels\n",
    "def display_predictions(images, labels, predictions, class_names):\n",
    "    for i in range(5):  # Display first 5 images\n",
    "        plt.figure()\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Actual: {class_names[np.argmax(labels[i])]} | Predicted: {class_names[np.argmax(predictions[i])]}')\n",
    "        plt.show()\n",
    "\n",
    "# Class names in CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "display_predictions(test_images, test_labels, predictions, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd56c1-440a-4a6d-90a0-d8ad3c95f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Open webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Preprocess the frame for the model\n",
    "    img = cv2.resize(frame, (224, 224))  # Resize frame to model input size\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Predict using the pre-trained model\n",
    "    pred = model.predict(img)\n",
    "    class_name = class_names[np.argmax(pred)]\n",
    "    \n",
    "    # Display the prediction on the frame\n",
    "    cv2.putText(frame, class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Real-time Image Classification', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8693a-75aa-4d01-a76e-89f3e79a8695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
